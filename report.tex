\documentclass[conference]{IEEEtran}
%\documentclass[12pt,a4paper,english]{report}
%\IEEEoverridecommandlockouts % The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{algorithm}
\usepackage{nicefrac}
\usepackage{footmisc}
\newcommand{\comment}[1]{}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Quantum-resistant digital signatures schemes for low-power IoT}

\author{\IEEEauthorblockN{1\textsuperscript{st} Hannes Hattenbach}
\IEEEauthorblockA{\textit{Computational Science} \\
\textit{Freie Universität}\\
Berlin, DE \\
hannes.hattenbach@fu-berlin.de}
}

\maketitle

\begin{abstract}
    % TODO
%*CRITICAL: Do Not Use Symbols, Special Characters, Footnotes, or Math in Paper Title or Abstract.
\end{abstract}

\begin{IEEEkeywords}
Internet of Things, Quantum Resistance, Secure Signatures, Power Constraint Devices
\end{IEEEkeywords}

%TODO 12 Pages

\section{Introduction}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
%done
    „principles of data integrity, message authentication, and nonrepudiation, are going to have profound aftermath on sensory data in terms of security and privacy.“ \cite{QR_sigs}
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%

The quantum revolution is coming. With quantum computers\footnote{compare section \ref{l:quantum_computing}} on the way to get more and more functional, people are fearing a loss of their security and privacy.
Or as \cite{QR_sigs} puts it, ``principles of data integrity, message authentication, and nonrepudiation, are going to have profound aftermath on sensory data in terms of security and privacy.''
That is because there are algorithms based on Shors algorithm that can forge signatures and decrypt encrypted messages whos security is based on discrete logarithms, including elliptic curves or prime factorization, like our most common schemes Elliptic Curve Digital Signature Algorithm (ECDSA) and RSA respectively are.
The quantum computer only needs access to the public keys of these asymmetric schemes.
The expenditure to forge a signature\footnote{that is considered secure under normal circumstances 
%noTODO: more precise? Unforgeable under chosen blabla
} with classic\footnote{we refer to classic if something is not directly leveraging entanglement or superposition} computers rises exponentially with increased key length, therefor being essentially unbreakable by classic computers.
A sufficient quantum computer on the other hand can derive a private key from a public key in polynomial time, therefor rendering these schemes broken.

That is why there are currently schemes under standardization\cite{PQClean-GH} that are based on other hard problems (not number theory) like so called lattice problems that cannot be that easily forged by quantum computers to save our privacy and security.

One of the use cases not directly coming to mind for the end user, but being as important non the less is signing sensitive sensor data in the Internet of Things (IoT).
Another problem coming up in the IoT compared to end-user-devices like Laptops and Smartphones though is the severe resource constraint-ness. 
The IoT consist of low power devices with very few storage and computing power.

In this paper i am going to evaluate existing signature schemes and their usage possibilities for the IoT regarding their performance metrics.

Therefor i am going to give a small introduction and background to quantum computing, being a little more detailed about their ability to break current encryption and signature standards.
In the next section i will give an overview over current candidates for Quantum Resistant (QR) Algorithms and giving performance metrics for those.
The following chapter will then focus on signature schemes in the IoT, starting with additional performance metrics relevant in the IoT.
With a little more details about two failed signature schemes to highlight potential pitfalls. 
And finally focussing on the best signature contender for the IoT so far: FALCON.

\section{Background}\label{background}
\subsection{Cryptography}\label{bg:crypto}
% done : already distinguish between : hashing, encryption (symmetric/asymmetric), signatures
Loosely speaking the main topic of cryptography can be divided into three groups.
The first of these groups is about one way functions, that shall not, as the name implies, be efficiently reversible.
If we create a smaller value of constant length from a bigger set of possibly variable length, we commonly refer to that as \textit{hashing}.
Cryptographic hashing is important for a variety of different applications like storing and matching passwords without the ability to infer any knowledge about that password.
Hashing itself can be used for the next pillar of cryptography: signatures.
Signature schemes are used to proof integrity or authenticity of any data.
A signature scheme consists of two parts, signing and verifying. 
The last group is encryption, which ensures privacy/confidentiality of any data, s.t. only the right entities can decrypt this data.
These schemes consist of the two parts encryption and decryption.
Additionally to those parts for signatures as well as encryption there needs to be process of key-generation.
We also differentiate between symmetric and asymmetric schemes. The first one has a different private and public key while the latter uses the same for de- and encryption.
More details about which of those schemes will be more or less endangered by quantum computing are in section \ref{l:quantum_computing} and \ref{l:qr-algs}.
\newline
In general we denote a signature scheme as the group of three algorithms \{GEN, SIGN, VER\} and a encryption scheme as \{GEN, ENC, DEC\}.
% noTODO ? Background section to put this in?
\subsection{Internet of Things}\label{bg:iot}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
%done
    - growing: over 3 billion rn \cite{QR_IoT}
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%

%discussion what the boundaries of iot compare different devices from linux devices rPI over 32bit Arm based processors with RTOS to 8bit micro controller like arduino/atmega
The IoT consists of a growing number (currently over 3 billion \cite{QR_IoT}) of devices of all sorts, having in common, that they communicate with each other and the environment rather than directly with humans.
Those devices range from automatic lights and smart home devices to tiny interconnected sensors in automatic fabrication.
A common characteristic though is, that most of these devices have limited processing power, flash storage and random access memory (RAM). 
A popular example for hobbyist IoT devices is the ESP32 from Espressif Microsystems.
They offer multiple Modules with up to 240Mhz Clock on the 32 IC, up to 16MiB Flash Storage and 320KiB RAM.
Which is more than other comparable devices but way less then a lower spec modern smartphone, with 10 times the frequency, 4GB of RAM and 64GB of storage.

Since the IoT consists of very different types of constrained nodes the IETF introduced different classes on which to classify IoT nodes, those can be seen in table \ref{IoT-classes}

\begin{table}
    \label{IoT-classes}
    \centering
    \caption{IETF IoT Classes}
    \begin{tabular}{|l | c c|}
        \hline
        Class & RAM & Flash \\
        \hline
        C0 & $<<$ 10 KiB & $<<$ 100 KiB\\
        C1 & ~ 10 KiB & ~ 100 KiB\\
        C2 & ~ 50 KiB & ~ 250 KiB\\
        \hline
    \end{tabular} 
\end{table}



\section{Quantum Resistant Security}
% XXX : more details about Shor and Grover
\subsection{Quantum Computing}\label{l:quantum_computing}
In contrast to classical computers, where information is processed in discrete states, a quantum computer leverages quantum mechanics to operate on so-called qubits - quantum objects that can be in superposition or entangled with each other. 
Opening a new kind of computing. 
One of the implications of that is, that it is now possible to factor large numbers in polynomial time using an algorithm developed by Shor \cite{Shor}. 
This algorithm uses a so-called Quantum-Fourier-Transform (QFT) to (probabilistically) get the frequencies of which a given function output occurs. That can be used together with euclids algorithm of finding the greatest common devisor to derive the prime factors. 
Prior to to quantum computers this was considered a hard problem that could only be computed in exponential time and was therefor considered practically impossible and was used as the basis-problem for RSA encryption.
Similar to that other common schemes like ECDSA can also be broken be slightly modified versions of Shors Algorithm.
\subsection{QR Algorithms}\label{l:qr-algs}
The two main algorithms with practical use cases that have a great speed-up compared to classical solutions, are the already introduced algorithm by Shor and an algorithm by Grover that can essentially reverses one-way functions by creating a superposition over all possible inputs, flipping all inputs with the wanted output (without knowing the inputs) and then flipping this state about its mean and repeating this process a lot of times \cite{Grover}.
While Shors algorithm provides exponential speed-up, Grovers algorithm only provides quadratic speed-up. It was also shown, that something similar to grovers algorithm but with exponential speedup is impossible \cite{Strengths&Weaknesses_QC}. 
Which implies that Hashing as well as symmetric cryptography stays relatively secure.
The quadratic speedup provided by quantum computers can easily be mitigated by doubling the key length.
On the other hand though, classical asymmetric cryptography is endangered by shors algorithm and quantum computers.

But not all asymmetric cryptography schemes are equally affected.
There are different proposals, both for QR encryption and for QR signature schemes.
They all do have in common though, that their security is not absolutely mathematically proven, but based upon assumptions.
We therefor need to consider a few measures that make schemes more or less secure.
\subsection{Performance Metrics}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
%done
    - Security Level (1-5, AES-128, SHA256, AES-192, SHA384, AES-256) \cite{QR_Iot_Lattice,Energy_comp}([7]) determined via grovers alg
    - no standard benchmark for quantum resistance \cite{QR_comparison} (NIST levels 1-5)
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%

Some performance metrics exist in QR schemes as well as in classic schemes.

Key length and key exchange message length \cite{QR_algs} are the more obvious ones.
The computing time also comes to mind as a performance metric. Here you need to differentiate between key generation, which is less important, since it should only occur rarely, and signing as well as signature verification \footnote{as well as its counterparts de- and encryption}.

Primarily in signatures another metric arises: how often can a private key be used before it needs to be switched out for another one, because the signature leaked information of the key.
This is not particularly relevant in most cases, as methods can be used to create long term procedures from short term procedures (those where a key can rarely, if ever, be recycled).
But it is relevant in the case of the IoT, since those methods require extra memory which is sparse in IoT-devices. Additionally they tend to make the signatures themselves longer, which also is not preferable in the IoT. \cite{QR_algs}

Additionally to more traditional performance metrics we somehow need to measure the security of given schemes against an attack by a quantum computer.
Sadly there is currently no standard benchmark to measure quantum resistance \cite{QR_comparison}, nevertheless the NIST created a standard that describes how secure a scheme is against a quantum computer by classifying it within 5 classes that can be determined with grovers algorithm \cite{QR_Iot_Lattice,Energy_comp}.
Those classes can be seen in table \ref{QR-classes}

\begin{table}
    \label{QR-classes}
    \centering
    \caption{QR Security classes and their traditional counterparts as classified by the NIST}
    \begin{tabular}{|l | c|}
        \hline
        Class & security compareable to \\
        \hline
        1 & AES-128 \\
        2 & SHA256 \\
        3 & AES-192 \\
        4 & SHA384 \\
        5 & AES-256 \\
        \hline
    \end{tabular} 
\end{table}

\subsection{Encryption}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
%done:
    knapsack problem - broken
    ''
    conjugacy search problem and related problems in braid groups, and the problem of solving
    multivariate systems of polynomials in finite fields
    '' also mostly broken or badly understood \cite{QR_algs}

    lattice based:
    - NTRUEncrypt (compare sigs)
    code based:
    - McEliece Error correction codes transformed - secure and fast (100micros) but keys are k*n matrices : millions of bits \cite{QR_algs} - not feasable 
    multivariate-based: decryption inefficent (''guess work'') \cite{QR_comparison}
    - Rainbow gigantic 22kbyte pubk
    Supersingular EC:
    not much in use and not super researched , one impl (SIKE) \cite{QR_comparison}
    Mixed schemes for backwards comp: neither fully safe nor efficent since 2 schemes need to be saved on device \cite{QR_comparison}

mostly code/lattice based implementations \cite{QR_comparison}
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%
QR encryption schemes can be based upon a multitude of different mathematical problems thought to be hard even for quantum computers.

Sadly, being thought of as secure mostly is not based upon actual rigorous proof but assumptions.
Therefor one problem that was used as a asymmetric encryption basis, the knapsack problem, was broken soon after its introduction by so-called approximate lattice reduction attacks \cite{QR_algs}.

Later iterations which include ``conjugacy search problem and related problems in braid groups, and the problem of solving
multivariate systems of polynomials in finite fields''\cite{QR_algs} have been under active research with the latter being broken after standardization and implementation \cite{QR_algs}.

Nevertheless there is an implementation of a multivariate-based scheme, called Rainbow, that is also currently a contender for standardization. But as an encryption scheme its not very suitable since the process of decrypting in multivariate based schemes requires some guessing work \cite{QR_comparison} which is essentially bad in IoT enviroments.
An additional problem that would make rainbow unsuitable for IoT use-cases is its big 22kB public key. While private keys can rather easily be shrunk in key-generation through help of a pseudo-random-generator, thats generally not the case for large public keys.

On the other hand we have a problem that is not yet very well researched and also not much in use, but has one implementation called SIKE. This problem is based upon supersingular elliptic Curves, which are itself a modification of elliptic curve problems that should make it quantum resistant. But since this topic isnt well-studied yet we are mostly left with Schmes based upon the following two thought-to-be quantum-hard problems.

The first one is so called code-based cryptography. Here the decoder has to correct errors of data that has been seemingly randomly shuffled, but only those with access to the private key can easily `unshuffle' the data to then use special error correction codes. 
The most researched one is called McEliece and even has quite fast ($100 \mu s$) and secure implementations. 
The main problem is, that the `shuffling' is realized through $k*n$ matrices that are generally big (millions of bits) and therefor unfeasible for constrained IoT devices.

The second one will be discussed in greater detail in section \ref{QR signatures}, since it is also used as one of the main problems for signature schemes.
Those schemes are called lattice based and also have some implementation with the most famous for encryption being NTRUEncrypt.

\subsection{Signatures} \label{QR signatures}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%

Signatures classify as
- Hash based
- Lattice based
- Multivariate polynomial based
- Code based
- Super-singular sogen based
\cite{QR_sigs}

hash based or lattice based:
- hash: XMSS, SPHINCS \cite{QR_IoT} (WOTS in IOTAs Tangle)
- lamport OT signature \cite{QR_algs} (as the name implies only useable one time - useless ; can precompute a bunch that are verifiable with the same pubk - useless since rare storage)
- lattice based signatures (high-d basis find shortest vector (SVP) or closest lattice vector to arbitrary point (CVP)) require megabits of basis - unfeasable NTRU reduce to kilobits by introducing symetry \cite{QR_algs,QR_comparison}
    -10-100* faster than conventional crypto
    Encryption : - vulnerable to CCA , lattice reduction techniques - padding scheme [30] , longer keys \cite{QR_algs}
    Signatures : - map message to vector, sign by solving (CVP) - leaks information about PrivK - broken after 400messages - dont give closest vektor but a close enough one - secure for 1 mrd (billion) sigs (still adviced to swap after 10mil) (okayish iniot since not so many massages)
    - proposals (2017: GPV, GLP, BLISS \cite{QR_IoT})

HBS vs Lattice:
    - SPHINCS (HBS) (intel XEON (wtf?!))
        - sign: 50mil clock cycles 
        - Ver: 1.6mil
        - Key-size: pub 1 ; private 1
        - Sig size: 41KB
    - BLISS (lattice) (arm M4)
        - 5.9mil
        - 1mil
        - 7; 2 (hm ouf, doch nicht so uff, sind ja nur KB)
        - 0.96

	HBS is well studied/understood/practiced lattice not and vulnerabilities discovered one after the other

	Stateful (wOTS, XMSS, LMS ..)
		„stateful digital signature scheme necessitates the main- tenance of the updated nonrepeated secret key upon each signature generation process. It is essential to keep track of nonrepeated key pairs, failing which will result in the degra- dation of the security of the cryptographic scheme“ ..sounds kinda whack to me

		MSS stores only prng seed and uses merkle trees -> managing state (used keys) on other side (because reusing key is imperative to security)

	Stateless(Sphincs)
		more expensive sig gen , since key pairs used in random order - BDS optimization no longer applicable

	Stateful if performance time and processor constrained, Stateless if energy/memory constrained
\cite{QR_sigs}


 code-based:   
- McEliece decrypt padded message digest - try thousands of paddings - signing takes 30secs, 4mb priv/pub KEY-size -not feasbale
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%
The other pillar of cryptography, signature schemes, is what we will focus on in greater detail.
As well as in encryption schemes we can differentiate between different underlying mathematical problems. Those are pretty much the same as in encryption schemes: 
Hash based,
Lattice based,
Multivariate polynomial based,
Code based,
Super-singular isogeny based.\cite{QR_sigs}

Rainbow is the only implementation of a QR signature that is a current contender for standardization that is neither lattice nor hash based.
And as already mentioned in the previous section it is multivariate based.

Since this sparsity of alternatives we we also focus on hash and lattice based signatures in this paper.

\subsubsection{Hash Based Signatures (HBS)}\label{HBS}
Hash based signatures have their security based upon the hardness of reversing Hashes or one-way functions.
The most easy one is the Lamport one time signature (OTS).\cite{QR_algs} 
That signature has essentially two private keys for every bit in the message digest. 
Let $n \in \mathbb{N}$ be the bit-length of the digest, then the secret key would be: \[k_\text{priv}= (S_{0,0},S_{0,1}) || (S_{1,0},S_{1,1})|| \dots || (S_{n,0},S_{n,1})\]
The advantage of those schemes is, that the private keys do not have to have any special characteristic that could be taken advantage of by a quantum computer to break anything.
They do have to be high entropy though, to not be easily forgeable with even a classic computer. 
These secrets are then hashed (with a one-way function $h$) and published as the public key \begin{align*}
    &k_\text{pub}= \\ &(h(S_{0,0}),h(S_{0,1})) || (h(S_{1,0}),h(S_{1,1}))|| \dots || (h(S_{n,0}),h(S_{n,1}))
\end{align*}

When a message is signed the signer just publishes the secret corresponding to every bit of the digest ($S{k,b}$ with $b$ being the bit-value in the $k$-th position ob the digest) s.t. everyone can hash that secret and see that this private keys are indeed the ones corresponding to the public key and the correct bit-value of the digest.
Signing as well as verifying are therefor rather easy operations with one disadvantage: the keys and the signature are super big.
But there are some rather easy improvements for this problem e.g. one could only sign the zeros, therefor reducing key sizes by a factor of $2$ as well as average signature sizes. To mitigate an attack that can flip digest-zeros to ones a checksum is added (that can only be decreased by flipping a one to zero, which is impossible if you do not know the pre-image (private key) of that location).
Another improvement often wrongly
\footnote{the merkle OTS has two parts, one that is similar to the Lamport scheme (which was then improved by Winternitz) and one that uses Merkle Hash Trees, which most of the literature refers to as the Merkle Signature, but is not a incessor of the winternitz scheme which does not use Merkle Trees \cite{merkle_ots}} 
cited as the successor to the Merkle OTS is the Winternitz Scheme (WOTS), which builds upon the same idea but uses a different (greater) basis $b$, which inturn makes the signing and verifying more computational expensive by needing to apply hashes $b$ times. The great advantage though is that the keys and signatures also decrease by a factor of $b$.
This can be a great advantage for IoT applications, since time is not as valuable as storage. Therefor WOTS is actually used in practice, for example as a signature on the IOTA distributed ledger. \cite{iota_wots}

A directly visible disadvantage of those schemes (as the name implies) is that they can trivially only be used one time, since most of the private key gets public with the signature. 
A trivial countermeasure would be to append the next public keys to the message and sign them as well, but thats not a good idea in most use cases, since you might as well just use symmetric cryptography which is also considered as quantum resistant as hashes.
Another idea would be to just publish a whole lot of private keys that can than be used one by one. But thats not a super brilliant idea since signer as well as verifier need to store all these keys which is specially infeasible in IoT scenarios (that have very constrained storage).
Schemes that can be used multiple times are smartly called multiple time signatures (MTS).

A smarter approach to simply publishing $n$ public keys and storing $n$ private keys was proposed by merkle \cite{merkle_ots}.
His approach uses so called merkle hash trees to make it possible to have a very small public key that can still verify $n$ signatures on the tradeoff that every signature now increases by a factor of $\log(n)$.
The idea is as follows:

\begin{algorithm}
\caption{GEN}\label{merkle gen v1}
    \begin{enumerate}
        \item generate $n=2^m$ random values, those are the private keys.
        \item for every private key $k_\text{priv}^i$ generate a one-time public key $k_\text{pub}^i=h(k_\text{priv}^i)$ (until here it is similar to a trivial MTS)
        \item hash every two `neighboring' keys $k_\text{pub}^i$, $k_\text{pub}^j$ together in pairs to generate $\nicefrac{n}{2}$ new hashes $h_{ij}=h(k_\text{pub}^i, k_\text{pub}^j)$ 
        \item hash those in pairs for the next iteration and repeat until the hash-tree is complete and we only have one root hash denoted as $k_\text{pub}$
        \item publish $k_\text{pub}$ that can now be used to verify $n$ signatures
    \end{enumerate}
\end{algorithm}

\begin{algorithm}
    \caption{SIGN}\label{merkle sig v1}
        \begin{enumerate}
            \item input message digest $M_i$
            \item sign as described for Lamport or Winternitz schemes (or other OTS schemes that generate the public key by hashing the private key): $S_i=\text{Sign}(M_i)$
            \item publish $S_i$ together with all hashes $h$ needed to iteratively generate the root hash $k_\text{pub}$. These are $m$ hashes.
        \end{enumerate}
    \end{algorithm}

\begin{algorithm}
    \caption{VER}\label{merkle ver v1}
        \begin{enumerate}
            \item input signature $(S_i,[h_{j},h_{i+2,j+2},\dots,h_{i-k}])$ and digest $M_i$ and already known multiple use public key $k_\text{pub}=h_{0-(n-1)}$
            \item hash $S_i$ to generate $k_\text{pub}^i$
            \item hash $k_\text{pub}^i=h_i$ together with $h_j$ to generate $h_{ij}$
            \item hash the value from previous step together with the next hash given by the signature
            \item repeat step 4) until the root hash $k_\text{pub}$ should be found (thats $m$ steps in total) return True if they are equal and False otherwise
        \end{enumerate}
    \end{algorithm}

This is already very useful for IoT actors that only need to verify, less so for sensors that still need to store all $n$ private keys. 
The computational cost is higher, caused by calculating all those hashes but thats commonly worth the tradeoff. 

On the other side (the signer) we need to store all $n$ private keys and calculate $m$ hashes every time we want to sign anything.
The second step can be skipped by also storing the hashes instead of calculating them, which increases the storage needed by a factor of $2$.
But thats infeasible for most storage constrained devices.
Therefor an additional tweak was applied to this algorithm:
Instead of randomly generating each private key and storing it, we use a Pseudo-Random-Generator (PRG) together with a seed and a counter to be able to generate every private key on the fly.
We can then iterativly generate our merkle tree and drop every nodes we already used to calculate the next parent hash without exceeding our RAM to generate the root hash to publish as the public multi time key.
For signing we can then create our private key again with the help of the PRG and again calculate all needed hashes iterativly the same way. 
But thats rather computationally expensive to recalculate the whole tree on every signature. 
Thats why we should cache as many in-between hashes as possible since every already stored hash reduces the computational expenses by a factor of 2.
The verification stays the same.

This scheme is know as the eXtendes Merkle Signature Scheme (XMSS) which also has some further variants and developments. \cite{QR_IoT }

Another disadvantage of schemes as described is the so-called statefulness, which means that the signer cannot just sign any message with a key after being reset, since some kind of state is needed that would be lost in a reset. \cite{QR_sigs} 
Besides that and even more impactful the verifier in an MSS needs to manage which keys/ part of the tree have already bin used, since reusing keys is imperative to the schemes security.

\subsubsection{Lattice Based Signatures (LBS)}
In a stateless scheme on the other hand, all you need to sign a message is a static private key.
That brings us to the other kind of signature schemes, ones that are more similar to traditional asymmetric crypto in the sense that they rely on not so trivial mathematical problem that is not easily algorithmically solveable. But instead of prime factorization or Elliptic curve calculation, this one seems to be hard to solve, even by a quantum computer. The problem for most of these schemes are Lattice Based.

A lattice in this case is a high-dimensional grid with only integer values. Or to be more precise: ``An n-dimensional lattice is the set of vectors that can be
expressed as the sum of integer multiples of a specific set of n
vectors, collectively called the basis of the lattice—note that
there are an infinite number of different bases that will all
generate the same lattice'' \cite{QR_algs}
To put it mathematically we can denote a Lattice $L$ as $L=\{\sum a_i*b_i : a_i \in \mathbb{Z}\}$ with $b_0,\dots,b_n$ being arbitrary basis vectors.
The mathematical problems that these schemes are based upon are the shortest vector problem (SVP) where a very short vector between to points need to be found or the Closest Vector Problem (CVP), where a lattice vector needs to be found that is closest to a given arbitrary point.
The directly arising problem though is, that to get reasonable security the basis (which serves as a private key) of the lattice needs to be in the range of megabits, which again is not ideal for our use-cases. That is why researchers developed the NTRU cryptosystem, that introduces certain symmetries to the lattice structure s.t. the key sizes can be much smaller while lowering the security only slightly.\cite{QR_algs,QR_comparison}
These new schemes are not only resistant to quantum attacks but also improve efficiency compared to traditional cryptography by having speed improvement by a factor of 10-100.
Sadly these lattice structures where vulnerable through lattice reduction techniques to Chosen Ciphertext Attacks (CCA) in the case of encryption schemes. But that was fixed with the introduction of a special padding scheme that made these attacks impossible but also increased the key-lengths \cite{QR_algs} .
In the case of signature schemes (like NTRUSign) the problem is even more severe.
The signature works by first mapping the message to a vector and then signing by solving the CVP for this vector. The problem is, that this procedure leaks information about the private key s.t. it was shown to be practically broken after only around 400 signatures.  To mitigate that issue the signer does not give the actual closest lattice vector, but a lattice vector that is close enough by a certain measure, but not necessary the closest. Therefor the leaked information is nearly neglectable and the signature and private key secure for around a billion signatures, although it is still advised to change the private key after around 10 million signatures. 
That is totally feasable compared to some MTS mentioned before since in many cases 10 million signatures is a whole lot.\cite{QR_IoT}

Actual Lattice based implementation that were proposed in 2017 are GPV, GLP and BLISS. But now there are newer and better implementations like FALCON that will be discussed in section \ref{falcon}.

\subsubsection{Comparison of HBS and LBS and Statefulness versus statelessness}
% done : compare BLISS to Sphincs and conclusion about stateful (HBS) and stateless (lattice)
At the time \cite{QR_sigs} was written, one the most common HBS was SPHINCS, which has not changed much, although it got a major update and has quite a few variants.
The most prominent LBS was called BLISS.
Suhail et al. then compared these two implementation and measured their performance.
BLISS (the LBS) was evaluated on a common IoT processor with ARMs M4 architecture while SPHINCS (the HBS) was evaluated on a intel XEON server processor. Still BLISS performed considerably better with exception of the key sizes. Results of their measurements are shown in table \ref{t:sphincsVSbliss}.

\begin{table}[]
    \centering
    \caption{Measurement results of comparing BLISS on M4 with SPHINCS on intel XEON as of \cite{QR_sigs}}
    \label{t:sphincsVSbliss}
    \begin{tabular}{|r | c  c|}
        \hline
        Metric & SPHINCS results & BLISS results\\
        \hline
        Signature clock-cycles & 50 million & 5.9 million \\
        Verification clock-cycles & 1.6 million & 1 million \\
        Public key size & 1KB & 7KB \\
        Private key size & 1KB & 2KB \\
        Signature size & 41KB & 960 bytes \\
        \hline
    \end{tabular}
\end{table}

We can therefor compare and somewhat conclude the pros and cons of LBS compared to HBS.
First of all it is to say, that HBS is already very well studied and bases its security upon already well established and praxis-tested Problems (Hashing), while Lattice based Security is still quite not new and in active research. It bases its security upon the CVP (or SVP) which itself is not studied that well, and a few vulnerabilities have already been shown \cite{QR_sigs}.
Another comparison, less about the underlying mathematical problems, but more from an applicational standpoint, is also from interest - statefulness.
We already know what stateful means, but Suhail et al. summarizes it rather well: 
``stateful digital signature scheme necessitates the main- tenance of the updated nonrepeated secret key upon each signature generation process. It is essential to keep track of nonrepeated key pairs, failing which will result in the degra- dation of the security of the cryptographic scheme'' 
We can already see that this would be a problem in many use-cases.
There are HBS schemes, like the above SPHINCS, that found a way to to make themselves stateless, but that comes with its own downsides, like in this case greatly increasing the key-generation expenses (compare table \ref{t:sphincsVSbliss}) , which is caused by using keys in a random order therefor making BDS optimization no longer applicable.

% TODO : can i somehow "hervorheben" this
It can therefor be concluded that stateful schemes are great in processor power/time constrained use cases while stateless schemes trade computing power for storage used and are therefor better in memory constrained use-cases. \cite{QR_sigs}

\section{QR Signatures in IoT}

We now have an overview of what kind of QR signature schemes exist with some focus on the two most promising underlying mathematical structures, hashes and lattices. In the following sections we will even more focus on what kind of actual implementation exist and which of them are feasable in an constrained environment.

\subsection{Performance Metrics in IoT}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
- key/ exchange message/ signature size 
- cache/ ram usage

- setup(ms)  lifetime, pubk size, privk size, sig

'' small sized public key, small digital 
signature and a range of supported hash output sizes is 
recommended''\cite{QR_Iot_Lattice}

- Stateful/less
- „signature and/or key sizes to running times and memory consumption to energy consumption „
- „From the software benchmark perspec- tive, the runtime of key generation, signing, and verification processes whereas from the hardware perspective, CPU cycles, key size, signature size, and energy consumption are among the targeted evaluation metrics. In general, the parameter sets are highly dependent on the underlying construction of a particular scheme.“
\cite{QR_sigs}

- most impls have quite large keys \cite{QR_comparison}
- key gen performance since many schemes have limited signatures \cite{QR_comparison}

- IoT evolves, when fast quantum is available iot will be better too  \cite{QR_comparison}
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%
First of all we need to establish what metrics we need to consider to evaluate which implementation are better suited and which are ill suited.
As mentioned in section \label{bg:iot} we have constraints in different fields. Those are primarily available energy therefor computing time and power as well as storage.
The storage itself can also be split into read only memory (ROM) and writeable memory (RAM).
Most operating systems (e.g. RIOT) split the available RAM again to expose two kinds of memory structures: stack and heap. These are often relevant since the stack and heap are used for different purposes, but since those are resizable at build time we wont focus on the differentiation between stack and heap.
Another memory differentiation that might be more relevant for future differentiation between stateful and stateless schemes is between persistant and volatile memory. 
For stateful schemes we need persistant writeable memory and probably quite a lot of it while stateless schemes typically require more computing time for every signature. Which brings us to the main metrics:

For each algorithm (GEN, SIGN,VER) we are interested in RAM/cache usage, execution time/energy consumption.
The significance of SIGN and VER performance is pretty obvious, but the GEN is also not to be forgotten since we have shown that most schemes either need to switch the keys because they leak over time or are simply just MTS signatures i.e. have to switch keys after a fixed amount of signatures, this amount is also influenced by available storage/time as we have shown in section \ref{HBS} with the merkle tree based signatures.
We are also interested of of different sizes that need to be either stored or transmitted vie the network, these are signature as well as private and public key sizes. In many schemes these sizes have been unusually big \cite{QR_comparison}.
The overall needed ROM for any algorithm is also from great interest since this is needed to say whether a scheme is applicable for different classes of IoT nodes as mentioned in section \ref{bg:iot}.

Another thing regarding these classes that we might want to mention is, that there is no Quantum Computer with even nearly sufficiently sized quantum registers yet and probably will not be in only a few years. Therefor it is probable that when these quantum computers exist, the IoT and their hardware will also have gotten much better. Still the right signature schemes are needed, but it might be okay to be a few kilobytes larger than these classes.  

\subsection{comparison of different signatures}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
Stack usage:
    name            & KeyGen    & Sign  & Verify
    Dilithium-3     & 50k       & 86k   & 54k
    newer dil(dyn)  & not meas  & 52k   & 36k \cite{update_sign}
    newer dil(sta)  & aheadOf t & 35k   & 19k \cite{update_sign}
    qTESLA-1        & 22k       & 29k   & 23k
    qTESLA-3        & 43k       & 28k   & 45k
    Falcon-5        & 120k      & 120k  & 120k
    newer FALCON    & not meas  & 42k   & 4.7k \cite{update_sign}

Clock cycles (10mil ~ 60ms (ARM M4 (168Mhz))):
    name        & KeyGen    & Sign  & Verify
    Dilithium-3 & 2.3m      & 8.3m  & 2.3m
    Dilithium-3 & 2.1       & 7.2   & 2.1 \cite{Energy_comp}
    Falcon-5    & 365m      & 165m  & 1m
    Falcon      & note meas & 75m   & 1m \cite{update_sign}
    qTESLA-3    & 30m       & 11m   & 2.2m
    \cite{QR_Iot_Lattice}

Hash-Based Sphincs promising since stateless, but many parameters to set \cite{QR_IoT_Energy}

as of \cite{QR_comparison} only schemes (out of ~50) with < 4kbit: SIKE and Round5 
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%
Since we now know what to look out for we can now compare results of measurements from different QR signature implementations.
In this comparison we already focused on schemes that could be relevant for the IoT (i.e. skipped schemes that had way to much memory/cpu usage).
The measurements seen in tables \ref{t:stack_comp} and \ref{t:clockcycles_comp}
where performed by \cite{QR_comparison},\cite{Energy_comp} and \cite{update_sign}

\begin{table}%[htbp]
    \caption{Comparison of Stack usages for different schemes and their operations ( - means that it has not bean measured while / means not applicable)}
    \label{t:stack_comp}
    \centering\begin{tabular}{| r | c c c |}
        \hline
        Implementation name                     & GEN (bytes) & SIGN (bytes) & VER (bytes)\\
        \hline
        Dilithium-3 \cite{QR_Iot_Lattice}       & 50k       & 86k   & 54k\\
        2021 Dilithium(dyn)\cite{update_sign}   & -         & 52k   & 36k\\
        2021 Dilithium(sta)\cite{update_sign}   & / \footnote{in the case of static Dilithium the keys where precomputed and directly stored in flash} & 35k   & 19k\\ %TODO: footnote visable?
        qTESLA-1 \cite{QR_Iot_Lattice}          & 22k       & 29k   & 23k\\
        qTESLA-3 \cite{QR_Iot_Lattice}          & 43k       & 28k   & 45k\\
        Falcon-5  \cite{QR_Iot_Lattice}         & 120k      & 120k  & 120k\\
        2021 FALCON \cite{update_sign}          & -         & 42k   & 4.7k\\
        \hline
    \end{tabular}
\end{table}

\begin{table}%[htbp]
    \caption{Comparison of clock cycles needed for the operations of different implementations, perfomed on ARM M4 chip which was clocked at 168Mhz therefor 10 million clockcycles equal roughly 60ms. Each value is a million clock cycles}
    \label{t:clockcycles_comp}
    \centering\begin{tabular}{| r | c c c |}
        \hline
        Implementation name                     & GEN           & SIGN         & VER \\
        \hline
        Dilithium-3 \cite{QR_Iot_Lattice}       & 2.3           & 8.3          & 2.3 \\
        Dilithium-3 \cite{Energy_comp}          & 2.1           & 7.2          & 2.1 \\ %TODO unclear major differences betwwen different measurements, should have conducted my own but no time -> future work
        2021 Dilithium(dyn)\cite{update_sign}   & -             & 29           & 3.4\\
        2021 Dilithium(sta)\cite{update_sign}   & -             & 8            & 1.5\\
        qTESLA-3 \cite{QR_Iot_Lattice}          & 30            & 11           & 2.2\\
        Falcon-5 \cite{QR_Iot_Lattice}          & 365           & 165          & 1\\
        2021 Falcon  \cite{update_sign}         & -             & 75           & 1\\
        \hline
    \end{tabular}
    
\end{table}

Unfortunately i could not find any reliable data about compiled code size \footnote{And i did not have enough resources left to measure it on my own, this could be part of future comparison research} (i.e. ROM usage) which is an important parameter, but the official NIST competition reference implementations \cite{nist_finalists_website} can give us a rough idea if we have a look how big the source code files are.

\begin{table}[htbp]
    \caption{uncompiled code size of reference implementations (different security levels (like Dilithium-3 and Dilithium-5) do not have any static changes reflected in code size)}
    \label{t:codesize_comp}
    \centering\begin{tabular}{| r | c |}
        \hline
        Scheme & Size\\
        \hline
        FALCON & 372KB \\
        Dilithium & 270KB\\
        SPHINCS+ & 180KB\\

        \hline
    \end{tabular}
\end{table}


%\subsection{Failed Signatures}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%

%\subsubsection{WalnutDSA}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
wahrscheinlich skippen da mir da hintergrund zu braid groups etc fehlt
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%

\subsection{qTESLA}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
not in the endgame but also not broken afaik
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%

\section{FALCON}\label{falcon}0
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
falcon-512 (L1):
pubk/sig 897/690 bytes (dil3: 1472/2701 ecdsa: 64)
keygen: 182m clk , 118mJ (dil3: 2.3m / 1.7mJ ecdsa 5mJ)
sign/ver: 23.5/0.345 mJ (dil3 5mJ/1.7mJ ecdsa 4mJ)

falcon-1024 (L5):
pubk/sig 1793/1330 bytes
keygen: 380m clk , 232mJ
sign/ver: 45.5/0.69 mJ
\cite{Energy_comp}

} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%


\section{Conclusion}
\comment{ %%%%%%%% NOTES %%%%%%%%%%%
- of course no protection against side channel etc 
- quantum fast evolving, active field of research
- smart home, smart campus, smart city
- quantum key distribution
\cite{QR_comparison}
} %%%%%%%%%%%%%%%% END %%%%%%%%%%%%%

\bibliographystyle{IEEEtran}
\bibliography{lit.bib, lit_specific.bib}

\end{document}
